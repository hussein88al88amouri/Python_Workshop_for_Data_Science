{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65eb99c2",
   "metadata": {},
   "source": [
    "**Scikit-Learn** is one of the most popular Python libraries for **machine learning**. \n",
    "\n",
    "It provides tools (methods and functions) for:\n",
    "- Loading datasets\n",
    "- Data preprocessing\n",
    "- Training models (supervised and unsupervised)\n",
    "- Making predictions\n",
    "- Evaluating performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1634d812",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ba937",
   "metadata": {},
   "source": [
    "### 3.1.1. Importing Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f85a86",
   "metadata": {},
   "source": [
    "Working with Iris dataset.\n",
    "\n",
    "The Iris dataset is a classic dataset for classification tasks in machine learning.\n",
    "It contains:\n",
    "- 150 samples of iris flowers\n",
    "\n",
    "With the following numeric features:\n",
    "- Sepal Length\n",
    "- Sepal Width\n",
    "- Petal Length\n",
    "- Petal Width \n",
    "\n",
    "And divided into 3 classess:\n",
    "- Iris-setosa\n",
    "- Iris-versicolor\n",
    "- Iris-virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ca264",
   "metadata": {},
   "source": [
    "Load Iris dataset `from sklearn.datasets import load_iris `\n",
    "\n",
    "you can import other datasets as long as they are maintained and porvided by Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49096830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Iris dataset\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc4cf4d",
   "metadata": {},
   "source": [
    "In machine learning, We usually separate the learning process from the testing process.\n",
    "\n",
    "This is achieved using `train_test_split ` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a514c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the method train_test_split \n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90c6bed",
   "metadata": {},
   "source": [
    "The recorded ovservation can be sekwed or have wide range of values.\n",
    "\n",
    "Best practices is to normalize and standarize the observations.\n",
    "\n",
    "import the pacakge for standarization `StandardScaler` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839316a4",
   "metadata": {},
   "source": [
    "We will use the Logistic Regression model.\n",
    "It is a machine learning algorithm used for classification tasks, which means it predicts the category or class of an observation rather than a continuous number.\n",
    "\n",
    "For example, given features of a flower (like petal length and width), Logistic Regression can predict whether the flower is Iris-setosa, Iris-versicolor, or Iris-virginica.\n",
    "It works by estimating the probability that a given observation belongs to each class and assigning it to the most likely one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dbe53a",
   "metadata": {},
   "source": [
    "To calcualte the quality and the perfromance of the model we will use different matheatical measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb356fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7289cf29",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7921ad6",
   "metadata": {},
   "source": [
    "### 3.1.2. Experment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b61007",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245b132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Features and target\n",
    "X = iris.data      # shape = (150, 4)\n",
    "y = iris.target    # shape = (150,)\n",
    "\n",
    "# Optional: view first 5 samples\n",
    "print(\"Features (first 5 rows):\\n\", X[:5])\n",
    "print(\"Target (first 5 rows):\", y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89019aa2",
   "metadata": {},
   "source": [
    "#### Splitting Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffb26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the data into 80% training and 20% testing\n",
    "# Use train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Explanation: This separates the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = None, None, None, None  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f31c41",
   "metadata": {},
   "source": [
    "#### Preprocessing (Standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5acdbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# TODO: Fit the scaler on the training data and transform both training and test sets\n",
    "# Use scaler.fit_transform(X_train) for training data\n",
    "# Use scaler.transform(X_test) for test data\n",
    "# Explanation: Standardization scales features to mean=0 and std=1, improving model performance\n",
    "X_train_scaled = None  # TODO\n",
    "X_test_scaled = None   # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a20c9a7",
   "metadata": {},
   "source": [
    "#### Training a Model (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014cb87",
   "metadata": {},
   "source": [
    "---\n",
    "- *Brief Math Behind Linear Regression*\n",
    "\n",
    "Linear Regression predicts a continuous value by fitting a **straight line** (or hyperplane in higher dimensions) to the training data.  \n",
    "\n",
    " **Model equation**:  \n",
    "\n",
    "$$\n",
    "\\hat{y} = \\mathbf{w}^\\top \\mathbf{x} + b\n",
    "$$  \n",
    "\n",
    "where:  \n",
    "-  $\\hat{y} $ = predicted value  \n",
    "-  $\\mathbf{x} $ = feature vector  \n",
    "-  $\\mathbf{w} $ = weights (coefficients)  \n",
    "-  $b $ = bias (intercept)  \n",
    "\n",
    "In two dimensional space, $\\mathbf{w}$ is simply the slope and $b$ is the intercept (offset in the y-axis).\n",
    "\n",
    " **Learning rule**: The weights are chosen to minimize the **Mean Squared Error (MSE)**:  \n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{m} \\sum_{i=1}^{m} \\big(y_i - \\hat{y}_i\\big)^2\n",
    "$$  \n",
    "\n",
    "where $i$ is the sample index and $m$ is the number of samples.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055004ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# TODO: Train the model on the scaled training data\n",
    "# Use model.fit(X_train_scaled, y_train)\n",
    "# Explanation: The model learns the patterns in the training data\n",
    "# Hint: Check documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be18d99b",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2869840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Predict on the test set\n",
    "# Use model.predict(X_test_scaled)\n",
    "# Explanation: The model predicts labels for unseen data\n",
    "y_pred = None  # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e5552",
   "metadata": {},
   "source": [
    "#### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate accuracy using accuracy_score(y_test, y_pred)\n",
    "accuracy = None  # TODO\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# TODO: Confusion matrix using confusion_matrix(y_test, y_pred)\n",
    "cm = None  # TODO\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30349b35",
   "metadata": {},
   "source": [
    "#### Visualizing the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7425681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TODO: Use seaborn heatmap to visualize 'cm'\n",
    "# Use sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "# Explanation: Heatmap helps understand which classes are predicted correctly or incorrectly\n",
    "sns.heatmap(None, annot=True, fmt=\"d\", cmap=\"Blues\")  # TODO\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbdb68a",
   "metadata": {},
   "source": [
    "#### Visualize Regression Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_scaled, y_train, color='blue', label='Actual Data')\n",
    "plt.plot(X_train_scaled, y_pred, color='red', label='Regression Line')\n",
    "plt.xlabel('Petal Length (cm)')\n",
    "plt.ylabel('Petal Width (cm)')\n",
    "plt.title('Linear Regression: Petal Width vs Petal Length (Setosa)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd5a51",
   "metadata": {},
   "source": [
    "#### Residuals Plot\n",
    "\n",
    "It shows whether the model under or over predict the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Residual is the difference between the actual value and the predicted value\n",
    "residuals = None\n",
    "\n",
    "plt.scatter(X_train_scaled, residuals, color='purple')\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.xlabel('Petal Length (cm)')\n",
    "plt.ylabel('Residual (y - y_pred)')\n",
    "plt.title('Residuals Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d3094",
   "metadata": {},
   "source": [
    "#### Squared Error Plot\n",
    "\n",
    "Highlights which points contribute most to the MSE and shows potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f81567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: it is the squared value of the difference between the actual and the predicted value.\n",
    "squared_errors = (y - y_pred) ** 2\n",
    "\n",
    "plt.bar(None, None, color='orange')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Squared Error')\n",
    "plt.title('Squared Errors per Sample')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
